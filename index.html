<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
     <!-- Global site tag (gtag.js) - Google Analytics -->
     <script async src="https://www.googletagmanager.com/gtag/js?id=G-4SK0H2Y80H"></script>
     <script>
       window.dataLayer = window.dataLayer || [];
       function gtag(){dataLayer.push(arguments);}
       gtag('js', new Date());
 
       gtag('config', 'G-4SK0H2Y80H');
     </script>

  <title>Tiange Xiang</title>
  
  <meta name="author" content="Tiange Xiang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="images/svl_logo.png">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body data-gr-c-s-loaded="true">
    <!-- This is the home page of Tiange Xiang, contents coming soon!
     -->
     <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Tiange Xiang &nbsp&nbsp 
                        <t style="font-family:verdana;font-size:94%;color:gray;">向天戈</t>      
                    </name>
                  </p>
                  <p>
                    I am a CS Ph.D. student in <a href="http://svl.stanford.edu/">Stanford Vision and Learning Lab</a> (SVL).<br> I'm advised by Sequoia Capital Prof. <a href="https://profiles.stanford.edu/fei-fei-li">Fei-Fei Li</a> and<br>co-advised by James H. Clark Prof. <a href="https://nmbl.stanford.edu/people/scott-delp/">Scott Delp</a>.
                    I am also closely working with Prof. <a href="https://stanford.edu/~eadeli/">Ehsan Adeli</a>.
                  </p>

                  <p>
                    I received my Bachelor's degree from The University of Sydney, where I was fortunate to work with Prof. <a href="https://weidong-tom-cai.github.io/">Weidong Cai</a>. I was awarded Honors Class I and <b>The University Medal</b>. 
                  </p>

                  <p>
                    I do research on AI & Computer Vision.
                  </p>
<!-- 
                  <p style="color: red;">I will be joining <a href="http://svl.stanford.edu/">Stanford Vision and Learning Lab</a> as a PhD student in Fall 2022!</p> -->

                  <p style="text-align: center;">
                    Contact: {X @ Y}, where X=xtiange, Y=stanford.edu 
                  </p>

                  <p style="text-align:center">
                    <!-- <a href="mailto:tiangex@outlook.com">Email</a> &nbsp/&nbsp -->
                    <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                    <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=sskixKkAAAAJ">Google Scholar</a> &nbsp/&nbsp
                    <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                    <a href="https://github.com/tiangexiang/">Github</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/xtiange/">Linkedin</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <!-- <img style="width:100%;max-width:100%" alt="profile photo" src="images/avator.jpg" class="hoverZoomLink"> -->
                  <img style="width:100%;max-width:100%" alt="profile photo" src="images/avator_dinosaur.jpg" class="hoverZoomLink">
                  <!-- <tr style="text-align: center;"> -->
                    <!-- {X @ Y}, where X=xtiange, Y=stanford.edu  -->
                  <!-- </tr> -->
                </td>
              </tr>
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                <td style="padding-bottom:20px;width:100%;vertical-align:middle">
                  <heading>Publications <t style="font-size:50%;color:gray;">( * indicates equal contributions)</t></heading>
                </td>
              </tr>
            </tbody></table>
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


                <!-- ==================A PAPER BLOCK STARTS==================== -->
               <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/occnerf.png' width="140%" style="padding-top:30px;">
                  </div>
                </td>
                <td style="width:60%;vertical-align:middle">
                    <papertitle style="font-size: 105%;">Rendering Humans from Object-Occluded Monocular Videos</papertitle>
                  
                  <br>
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="https://www.linkedin.com/in/adam-sun/">Adam Sun</a>,
                  <a style="color: gray;" href="https://jiajunwu.com/">Jiajun Wu</a>,
                  <a style="color: gray;" href="http://stanford.edu/~eadeli/">Ehsan Adeli</a>,
                  and <a style="color: gray;" href="https://profiles.stanford.edu/fei-fei-li?releaseVersion=10.5.2">Li Fei-Fei</a>
                  <br>
                                <!-- <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023 -->
                                <em>ICCV</em>, 2023
                  <br>
                  <br>
                  We rendered human from object occluded videos.
                  <br>
                  [
                  <a href="https://arxiv.org/pdf/2308.04622.pdf">paper</a> &nbsp/&nbsp
                  <a href="https://github.com/tiangexiang/OccNeRF">code</a>
                  ]
                </td>
              </tr> 
              <!-- ==================A PAPER BLOCK ENDS==================== -->


               <!-- ==================A PAPER BLOCK STARTS==================== -->
               <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/squid.jpg' width="130%" style="padding-top:15px;">
                  </div>
                </td>
                <td style="width:60%;vertical-align:middle">
                    <papertitle style="font-size: 105%;">In-painting Radiography Images for Unsupervised Anomaly Detection</papertitle>
                  
                  <br>
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="https://scholar.google.com/citations?user=lU3wroMAAAAJ&hl=en">Yixiao Zhang</a>,
                  <a style="color: gray;" href="https://scholar.google.com/citations?user=rIJ99V4AAAAJ&hl=en">Yongyi Lu</a>,
                  <a style="color: gray;" href="https://www.cs.jhu.edu/~ayuille/">Alan L. Yuille</a>,
                  <a style="color: gray;" href="https://chaoyivision.github.io/">Chaoyi Zhang</a>,
                  <a style="color: gray;" href="https://weidong-tom-cai.github.io/">Weidong Cai</a>, <br>
                  and <a style="color: gray;" href="https://www.zongweiz.com/">Zongwei Zhou</a>
                  <br>
                                <!-- <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023 -->
                                <em>CVPR</em>, 2023
                  <br>
                  <br>
                  We re-formulated unsupervised anomaly detection as semantic-sapce in-painting.
                  <br>
                  [
                  <a href="https://arxiv.org/pdf/2111.13495.pdf">paper</a> &nbsp/&nbsp
                  <a href="https://github.com/tiangexiang/SQUID">code</a>
                  ]
                </td>
              </tr> 
              <!-- ==================A PAPER BLOCK ENDS==================== -->

              <!-- ==================A PAPER BLOCK STARTS==================== -->
              <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/mindvis.png' width="85%" style="padding-top:15px;padding-left:35px">
                  </div>
                </td>
                <td style="width:60%;vertical-align:middle">
                    <papertitle style="font-size: 105%;">Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision Decoding</papertitle>
                  
                  <br>
                  <a style="color: gray;" href="https://neuroimaginglab.org/index.html">Zijiao Chen</a>*,
                  <a style="color: gray;" href="https://www.linkedin.com/in/qing-jiaxin-188984119/?originalSubdomain=hk">Jiaxin Qing</a>*,
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="https://neuroimaginglab.org/index.html">Wan Lin Yue</a>,
                  and <a style="color: gray;" href="https://scholar.google.com.sg/citations?user=4Z1S3_oAAAAJ&hl=en">Juan Helen Zhou</a>
                  <br>
                                <!-- <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023 -->
                                <em>CVPR</em>, 2023
                  <br>
                  <br>
                  We decoded photo-realistic visual stimuli from fMRI brain signals.
                  <br>
                  [
                  <a href="https://mind-vis.github.io/">project page</a> &nbsp/&nbsp
                  <a href="https://github.com/zjc062/mind-vis">code</a> &nbsp/&nbsp
                  <a href="https://arxiv.org/pdf/2211.06956.pdf">paper</a>
                  ]
                </td>
              </tr> 
              <!-- ==================A PAPER BLOCK ENDS==================== -->


              <!-- ==================A PAPER BLOCK STARTS==================== -->
              <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/ddm2.png' width="130%" style="padding-top:35px;">
                  </div>
                </td>
                <td style="width:60%;vertical-align:middle">
                    <papertitle style="font-size: 105%;">DDM<sup>2</sup>: Self-Supervised Diffusion MRI Denoising with Generative Diffusion Models</papertitle>
                  
                  <br>
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="https://scholar.google.com/citations?user=oAXHlRMAAAAJ&hl=fr">Mahmut Yurt</a>,
                  <a style="color: gray;" href="https://profiles.stanford.edu/ali-syed">Ali B Syed</a>,
                  <a style="color: gray;" href="https://med.stanford.edu/setsompoplab.html">Kawin Setsompop</a>, and
                  <a style="color: gray;" href="https://med.stanford.edu/mimi.html">Akshay Chaudhari</a>
                  <br>
                  <!-- <em>International Conference on Learning Representations (ICLR)</em>, 2023 -->
                  <em>ICLR</em>, 2023
                  <br>
                  <br>
                  We achieved self-supervised MRI denoising through generative diffusion models.
                  <br>
                  [
                  <a href="https://arxiv.org/pdf/2302.03018.pdf">paper</a> &nbsp/&nbsp
                  <a href="https://github.com/StanfordMIMI/DDM2">code</a>
                  ]
                </td>
              </tr> 
              <!-- ==================A PAPER BLOCK ENDS==================== -->

              <!-- ==================A PAPER BLOCK STARTS==================== -->
              <!-- <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/ads.jpg' width="130%" style="padding-top:25px;">
                  </div>
                </td>
                <td style="width:50%;vertical-align:middle">
                    <papertitle style="font-size: 105%;">In Guiding Body Meshes to Global 3D Coordinates from a Monocular RGB Image</papertitle>
                  
                  <br>
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="https://www.linkedin.com/in/yutian-lei-0ba3a314b/?originalSubdomain=cn">Yutian Lei</a>,
                  <t style="color: gray;" >Jun Liu</t>, and
                  <a style="color: gray;" href="https://www.donghuang-research.com/">Dong Huang</a>
                  <br>
                                <em>Under review</em>
                  <br>
                  <br>
                  We achieved person detection, SMPL regression, 'real' camera-coordinate 3D localization in one hybrid-framework.
                  <br>
                  [
                  paper &nbsp/&nbsp
                  code
                  ]
                </td>
              </tr>  -->
              <!-- ==================A PAPER BLOCK ENDS==================== -->
              
                <!-- ==================A PAPER BLOCK STARTS==================== -->
              <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/curvenet.jpg' width="130%" style="padding-top:45px;">
                  </div>
                </td>
                <td style="width:50%;vertical-align:middle">
                    <papertitle style="font-size: 105%;">Walk in the Cloud: Learning Curves for Point Clouds Shape Analysis</papertitle>
                  
                  <br>
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="https://chaoyivision.github.io/">Chaoyi Zhang</a>,
                  <a style="color: gray;" href="http://www.cse.unsw.edu.au/~ysong/">Yang Song</a>,
                  <a style="color: gray;" href="https://github.com/Crane-YU">Jianhui Yu</a>, and
                  <a style="color: gray;" href="https://weidong-tom-cai.github.io/">Weidong Cai</a>
                  
                  <br>
                                <!-- <em>IEEE/CVF International Conference on Computer Vision (ICCV)</em>, 2021 -->
                                <em>ICCV</em>, 2021
                  <br>
                  <br>
                  We proposed a geometry-aware feature aggregation operator for point cloud analysis.
                  <br>
                  [
                  <a href="https://curvenet.github.io/">project page</a> &nbsp/&nbsp
                  <a href="https://arxiv.org/pdf/2105.01288.pdf">paper</a> &nbsp/&nbsp
                  <a href="https://github.com/tiangexiang/CurveNet">code</a>
                  ]
                </td>
              </tr> 
              <!-- ==================A PAPER BLOCK ENDS==================== -->
              <!-- ==================A PAPER BLOCK STARTS==================== -->
              <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/mia.jpg' width="130%" style="padding-top:40px;">
                  </div>
                </td>
                <td style="width:50%;vertical-align:middle">
                    <papertitle style="font-size: 105%;">Towards Bi-directional Skip Connections in Encoder-Decoder Architectures and Beyond</papertitle>
                  
                  <br>
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="https://chaoyivision.github.io/">Chaoyi Zhang</a>,
                  <a style="color: gray;" href="https://scholar.google.com.au/citations?user=_uPPBqUAAAAJ&hl=en">Xinyi Wang</a>,
                  <a style="color: gray;" href="http://www.cse.unsw.edu.au/~ysong/">Yang Song</a>,
                  <a style="color: gray;" href="https://www.linkedin.com/in/dongnan-liu-6ab802161/">Dongnan Liu</a>, 
                  <a style="color: gray;" href="https://sites.pitt.edu/~heh45/">Heng Huang</a>, <br>
                  and <a style="color: gray;" href="https://weidong-tom-cai.github.io/">Weidong Cai</a>
                  
                  <br>
                      <!-- <em>Medical Image Analysis</em>, 2022 -->
                      <em>MedIA</em>, 2022
                  <br>
                  <br>
                  An efficient and light-weight encoder-decoder network with SOTA performances.
                  <br>
                  [
                  <a href="https://bionets.github.io/">project page</a> &nbsp/&nbsp
                  <a href="https://arxiv.org/pdf/2203.05709.pdf">paper</a>
                  ]
                </td>
              </tr> 
              <!-- ==================A PAPER BLOCK ENDS==================== -->

              <!-- ==================A PAPER BLOCK STARTS==================== -->
              <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/bixnas.jpg' width="130%" style="padding-top:70px;">
                  </div>
                </td>
                <td style="width:50%;vertical-align:middle;padding-top:30px;">
                    <papertitle style="font-size: 105%;">BiX-NAS: Searching Efficient Bi-directional Architectures for Medical Image Segmentation</papertitle>
                  
                  <br>
                  <a style="color: gray;" href="https://scholar.google.com.au/citations?user=_uPPBqUAAAAJ&hl=en">Xinyi Wang</a>*,
                  <strong>Tiange Xiang</strong>*,
                  <a style="color: gray;" href="https://chaoyivision.github.io/">Chaoyi Zhang</a>,
                  <a style="color: gray;" href="http://www.cse.unsw.edu.au/~ysong/">Yang Song</a>,
                  <a style="color: gray;" href="https://www.linkedin.com/in/dongnan-liu-6ab802161/">Dongnan Liu</a>, 
                  <a style="color: gray;" href="https://sites.pitt.edu/~heh45/">Heng Huang</a>, <br>
                  and <a style="color: gray;" href="https://weidong-tom-cai.github.io/">Weidong Cai</a>
                  
                  <br>
                                <!-- <em>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</em>, 2021 -->
                                <em>MICCAI</em>, 2021
                  <br>
                  <br>
                  We proposed a NAS method to search efficient bi-directional architectures.
                  <br>
                  [
                  <a href="https://bionets.github.io/">project page</a> &nbsp/&nbsp
                  <a href="https://arxiv.org/pdf/2106.14033.pdf">paper</a> &nbsp/&nbsp
                  <a href="https://github.com/tiangexiang/BiX-NAS">code</a>
                  ]
                </td>
              </tr> 
              <!-- ==================A PAPER BLOCK ENDS==================== -->

            <!-- ==================A PAPER BLOCK STARTS==================== -->
            <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/bionet.jpg' width="130%" style="padding-top:65px;">
                  </div>
                </td>
                <td style="width:50%;vertical-align:middle;padding-top:30px;">
                    <papertitle style="font-size: 105%;">BiO-Net: Learning Recurrent Bidirectional Connections for Encoder-Decoder Architecture</papertitle>
                  
                  <br>
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="https://chaoyivision.github.io/">Chaoyi Zhang</a>,
                  <a style="color: gray;" href="https://www.linkedin.com/in/dongnan-liu-6ab802161/">Dongnan Liu</a>, 
                  <a style="color: gray;" href="http://www.cse.unsw.edu.au/~ysong/">Yang Song</a>,
                  <a style="color: gray;" href="https://sites.pitt.edu/~heh45/">Heng Huang</a>, <br>
                  and <a style="color: gray;" href="https://weidong-tom-cai.github.io/">Weidong Cai</a>
                  
                  <br>
                        <!-- <em>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</em>, 2020 -->
                        <em>MICCAI</em>, 2020
                  <br>
                  <br>
                  We proposed bi-directional skip connections in the encoder-decoder architecture.
                  <br>
                  [
                  <a href="https://bionets.github.io/">project page</a> &nbsp/&nbsp
                  <a href="https://arxiv.org/pdf/2007.00243.pdf">paper</a> &nbsp/&nbsp
                  <a href="https://github.com/tiangexiang/BiO-Net">code</a>
                  ]
                </td>
              </tr> 

             <!-- ==================A PAPER BLOCK STARTS==================== -->
            <tr>
                <td style="width:30%;vertical-align:middle">
                  <div class="one">
                    <img src='images/dsnet.jpg' width="130%" style="padding-top:70px;">
                  </div>
                </td>
                <td style="width:50%;vertical-align:middle;padding-top:30px;">
                    <papertitle style="font-size: 105%;">DSNet: A Weakly-Supervised Dual-Stream Framework for Effective Gigapixel Pathology Image Analysis</papertitle>
                  
                  <br>
                  <strong>Tiange Xiang</strong>,
                  <a style="color: gray;" href="http://www.cse.unsw.edu.au/~ysong/">Yang Song</a>,
                  <a style="color: gray;" href="https://chaoyivision.github.io/">Chaoyi Zhang</a>,
                  <a style="color: gray;" href="https://www.linkedin.com/in/dongnan-liu-6ab802161/">Dongnan Liu</a>, 
                  
                  <a style="color: gray;" href="https://www.microsoft.com/en-us/research/people/meic/">Mei Chen</a>,
                  <a style="color: gray;" href="http://scholar.harvard.edu/fanzhang">Fan Zhang</a>, <br>
                  <a style="color: gray;" href="https://sites.pitt.edu/~heh45/">Heng Huang</a>, 
                  <a style="color: gray;" href="https://scholar.harvard.edu/laurenjodonnell">Lauren O'Donnell</a>,
                  and <a style="color: gray;" href="https://weidong-tom-cai.github.io/">Weidong Cai</a>
                  <br>
                                <!-- <em>IEEE Transactions on Medical Imaging</em>, 2022  -->
                                <em>TMI</em>, 2022 
                  <br>
                  <br>
                  We proposed to combine global-local clues for weakly-supervised WSI analysis.
                  <br>
                  [
                  <a href="https://arxiv.org/pdf/2109.05788.pdf">paper</a>
                  ]
                </td>
              </tr> 
              <!-- ==================A PAPER BLOCK ENDS==================== -->
            </tbody></table>







            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding-bottom:20px;width:100%;vertical-align:middle">
                <heading>Pre-prints</heading>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody></tbody>
          <!-- ==================A PAPER BLOCK STARTS==================== -->
          <tr>
            <td style="width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/dropgraph.jpg' width="130%" style="padding-top:10px;">
              </div>
            </td>
            <td style="width:60%;vertical-align:middle">
                <papertitle style="font-size: 105%;">Partial Graph Reasoning for Neural Network Regularization</papertitle>
              
              <br>
              <strong>Tiange Xiang</strong>,
              <a style="color: gray;" href="https://chaoyivision.github.io/">Chaoyi Zhang</a>,
              <a style="color: gray;" href="http://www.cse.unsw.edu.au/~ysong/">Yang Song</a>,
              <a style="color: gray;" href="https://scholar.google.com/citations?user=ADyo_cAAAAAJ&hl=en&oi=ao">Siqi Liu</a>, 
              <t style="color: gray;" >Hongliang Yuan</t>, and
              <a style="color: gray;" href="https://weidong-tom-cai.github.io/">Weidong Cai</a>
              <br>
              <br>
              We formulated regularization as generative distortions through learnable graphs. 
              <br>
              [
              <a href="https://dropgraph.github.io/">project page</a> &nbsp/&nbsp
              <a href="https://arxiv.org/pdf/2106.01805.pdf">paper</a>
              ]
            </td>
          </tr> 
          <!-- ==================A PAPER BLOCK ENDS==================== -->

          <!-- ==================A PAPER BLOCK STARTS==================== -->
          <tr>
            <td style="width:30%;vertical-align:middle">
              <div class="one">
                <img src='images/denoise.jpg' width="130%" style="padding-top:50px;">
              </div>
            </td>
            <td style="width:50%;vertical-align:middle">
                <papertitle style="font-size: 105%;">Two-Stage Monte Carlo Denoising with Adaptive Sampling and Kernel Pool</papertitle>
              
              <br>
              <strong>Tiange Xiang</strong>,
              <t style="color: gray;" >Hongliang Yuan</t>,
              <a style="color: gray;" href="https://scholar.google.com.hk/citations?user=wTJ83eEAAAAJ&hl=en">Haozhi Huang</a>, and
              <t style="color: gray;" >Yujin Shi</t>
              <br>
              <br>
              We achieved real-time denoising for online rendering at adaptive spp counts
              <br>
              [
              <a href="https://arxiv.org/pdf/2103.16115.pdf">paper</a>
              ]
            </td>
          </tr> 
          <!-- ==================A PAPER BLOCK ENDS==================== -->
        </tbody></table>
              



              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                <tr>
                  <td>
                    <heading>Service</heading>
                  </td>
                </tr>
              </tbody></table>
              <table width="100%" align="center" border="0" cellpadding="20"><tbody>
                <li>
                    Conference reviewer for CVPR(2021,2022,2023,2024), MICCAI(2021, 2022, 2023), ICCV 2023, ICML 2022, ECCV 2022, NeurIPS 2022, WACV 2023.
                </li>
                <li>
                  Journal reviewer for IEEE TPAMI, IEEE TIP, IEEE TMI, Neurocomputing, Scientific Report.
                </li>
              </tbody></table>
        
      </table>
    
    <div style="margin:10px auto;width: 200px;height: 100px; pointer-events: none;">
        <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=ZfI9vrWx0CCuk1XZ0ew3Cg0wQc7izTqfrzAaAWx8Yck&cl=ffffff&w=a"></script>
    </div>

    <br>
    <hr>
	<p style="font-size:10;text-align: center;"><i>Last updated on 05/11/2023</i>;&nbsp;&nbsp;&nbsp;&nbsp; Template from <a href="https://jonbarron.info/">here</a></p>
</body></html>